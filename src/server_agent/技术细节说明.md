# 项目技术细节说明
## 整体运行流程
启动后端，需要在终端内运行 uvicorn main:app --reload --port 8000 --env-file .env --host 0.0.0.0

这段命令具体会发生如下事件:
- 解析目标：main:app


    main：表示要导入的 Python 模块（main.py）

    app：该模块里暴露的 ASGI 应用对象（通常是 app = FastAPI()），或是一个可调用的工厂（返回 ASGI 应用）

    过程：

        Uvicorn 调用 importlib 导入 main

        取出其中的 app 对象（或调用工厂函数得到实例）

            当你运行 uvicorn main:app 时，Uvicorn 想拿到那个 app 对象（ASGI 应用）。要拿到它，必须先导入 main 这个模块，然后在模块里查找名为 app 的变量。
        
            在 Python 里，“导入模块”本身就会执行该模块顶层的所有代码（赋值、函数定义、创建对象等）

        校验它是一个符合 ASGI 规范的可调用（即可 await app(scope, receive, send)）

    若 main.py 不在当前工作目录的 PYTHONPATH，或没有 app，会启动失败并报错

- 启动 ASGI 服务器（监听端口）


    打开一个 TCP 监听：默认 host=127.0.0.1（仅本机可访问），port=8000（由 --port 指定）

    建立事件循环（asyncio；若安装了 uvloop 且未禁用，会使用 uvloop 加速）

    这边的事件循环会负责异步处理main:app的各项功能，当你的代码在某处 await（网络/文件/子进程/睡眠）时，事件循环会挂起这个协程，转去运行其他已就绪的协程；等 I/O 就绪或定时器到点，再把被挂起的协程恢复到 await 的下一行。没有循环，await 就没意义；有了循环，单线程也能高并发。
    
    要保证协程流畅运行，不要在请求处理中做阻塞调用（如 time.sleep()、大文件同步读写、CPU 密集计算），会把整个事件循环卡死，所有请求都跟着卡
    
    初始化 HTTP/WebSocket 协议栈（httptools/websockets），准备接收请求

    想让局域网其他机器可访问：加 --host 0.0.0.0，例如

    uvicorn main:app --host 0.0.0.0 --port 8000

- 触发应用的生命周期事件

    
    加载到 app 后，Uvicorn 会在真正开始处理请求前触发 ASGI lifespan：

    startup：如你在 FastAPI 里 @app.on_event("startup") 做的初始化（加载模型、连数据库、启动 MCP 客户端等）。

    （停止时会触发 shutdown：做清理、关闭子进程等）

- 开启自动重载：--reload


    开启一个文件监视进程（watcher） + 服务子进程（worker） 的双进程模式：

    watcher 进程：监听代码文件变更（默认当前项目目录）。一旦检测到变更：

    先平滑地关闭旧 worker（触发 shutdown）

    再启动新 worker，重新导入模块、触发 startup

    worker 进程：真正监听 :8000，处理所有 HTTP/WS 请求。

    这意味着：

    保存代码后浏览器刷新即可，服务自动重启。

    控制台会看到两行 “Started reloader process … / Started server process …”。

    常见配套参数（知道即可）：

    --reload-dir DIR 指定额外监控目录

    --env-file .env 启动时加载环境变量文件

    生产环境一般不开 --reload；而是用进程管理（如 gunicorn -k uvicorn.workers.UvicornWorker -w 4）或容器编排。

- 请求处理的链路（收到一次 HTTP 请求时）


    客户端到达 127.0.0.1:8000 → Uvicorn 接收连接。
    
    Uvicorn 解析 HTTP 报文，组装 ASGI scope/receive/send。
    
    调用你的 app（路由匹配、依赖注入、中间件、业务逻辑）。
    
    生成响应，Uvicorn 写回给客户端（支持 keep-alive、压缩等）。
    
    FastAPI 的交互文档 /docs 与 /redoc 也是通过这条链路提供的。

### 启动服务器时发生的事件

前面提到启动时会自动触发startup()，而startup()是这么写的
```python
@app.on_event("startup")
async def startup():
    global _initialized
    async with _init_lock:#进入一个 异步锁（_init_lock = asyncio.Lock() 通常在模块顶层创建）。作用：避免竞态——如果有多个并发路径可能触发初始化（例如你在路由里也做了“懒加载兜底”），只有第一个协程能进入临界区，其它协程会等待；等初始化完成再放行。
        if not _initialized:#双保险。即使多个并发都到达这里，只有第一个会执行真正的初始化；后面进来的看到标记已置位，就直接跳过
            await agent.init_tools()
            _initialized = True
```
设定了全局变量_initialized，这样其他协程才可以知道初始化是否已经完成，未完成则挂起等待

agent.init_tools()则是我们目前的初始化要做的事情，后续在这边还要根据需求进一步添加功能

剩下的就是app的各项功能，在遇到各种get和post请求时要如何处理，这边就不展开了

### agent的初始化

前文提到，uvicorn main:app --reload --port 8000 --env-file .env时，实际上是需要运行整个main文件，然后从中去寻找app这个对象的

而main开头就有这么一段
```python
agent = MCPAgent()
```
所以启动服务器的同时就已经实例化了一个MCPAgent，我们来看看MCPAgent具体承担了什么功能

MCPAgent的初始化第一行就做了这么一件事
```python
self.client = AsyncOpenAI(
            base_url=BASE_URL,
            api_key=OPENAI_API_KEY,
            timeout=LLM_CLIENT_TIMEOUT_SEC,    # 负责和LLM直接对话，将用户的输入格式化传入给LLM，将LLM的格式化输出解析为具体行为，如回复直接传给用户，调用工具则进行调用
            # max_retries=0,  # 如需禁用 SDK 的自动重试可打开
        )
```
这个client负责和LLM直接进行交互,顺便要采用异步版本，防止LLM没有响应阻塞服务器进程
```python
resp = self.client.chat.completions.create(
                model=MODEL,
                messages=messages,
                tools=self.tools,#工具列表在这边暴露给模型
                tool_choice="auto",
                temperature=0.2,
            )
```
这样就会将目前的信息发送给LLM并等待LLM的回复，同时工具也是这么暴露给LLM的

同时app在启动时还调用了
```python
await agent.init_tools()
```
这个函数是这样的
```python
    async def init_tools(self):
        self.mcp_clients = await load_all_clients()
        self.tools.clear()
        self._tool_map.clear()
        # 汇总所有 MCP 服务器的工具
        for mc in self.mcp_clients:
            tl = await mc.list_tools()
            for t in tl:
                name = t["name"]
                # 如需防止不同服务器重名工具冲突，这里可引入命名空间（如 f"{mc.server_name}.{name}"）
                self.tools.append({
                    "type": "function",
                    "function": {
                        "name": name,
                        "description": t["description"],
                        "parameters": t["input_schema"]  # 直接使用
                    }
                })  # 把 MCP 的工具描述（t["name"] / t["description"] / t["input_schema"]）转换为 OpenAI 工具列表（self.tools）——这样模型才能用 tool_calls 方式“请求调用”这些工具
                self._tool_map[name] = mc
```
读取了所有工具，并把每个工具映射到了对应的mcp_client，这边的mc是一个个MCPClient
```python
async def load_all_clients() -> List[MCPClient]:
    servers = os.getenv("MCP_SERVERS", "python tools_server.py").split(";")
    clients = []
    for s in servers:
        c = MCPClient(s.strip())
        await c.__aenter__()
        clients.append(c)
    return clients
```
这边读取了环境变量MCP_SERVERS，我们看.env文件，就可以看见环境变量是这么个形式：

MCP_SERVERS=C:\Users\Chen\.conda\envs\P313\python.exe tools_server.py

指定了解释器和服务器对应的python脚本，同时注意到分割符是";"，因此要添加新的服务器就要用";"分割

而接下来实际上是把C:\Users\Chen\.conda\envs\P313\python.exe tools_server.py作为参数传给了MCPClient的初始化函数
```python
    def __init__(self, launch_cmd: str):
        """
        launch_cmd 示例：
        - "python tools_server.py"
        - 或 "node dist/server.js"
        """
        self.launch_cmd = launch_cmd
        self.exit_stack = AsyncExitStack()
        self.session: ClientSession | None = None#这边的session仍然还是一个空对象，ClientSessio只是一个类型提示，后续才完成session的初始化
```
初始化函数做的事情实际上不多，主要是为了防止阻塞进程，真正启动一个client所需要做的事情要放到协程aenter中
```python
    async def __aenter__(self):
        parts = shlex.split(self.launch_cmd, posix=(os.name != "nt"))
        params = StdioServerParameters(command=parts[0], args=parts[1:], env=None)
        stdio_transport = await self.exit_stack.enter_async_context(stdio_client(params))
        stdio, write = stdio_transport
        self.session = await self.exit_stack.enter_async_context(ClientSession(stdio, write))
        await self.session.initialize()
        return self
```
```python
params = StdioServerParameters(command=parts[0], args=parts[1:], env=None)
```

构造“用 stdio 启动 MCP 服务器”的参数对象：

command=parts[0]：要运行的可执行文件（如 python.exe）。

args=parts[1:]：传给它的参数（如 tools_server.py）。

env=None：使用当前进程的环境变量；如果要注入/覆盖环境，可传入一个 dict。
```python
stdio_transport = await self.exit_stack.enter_async_context(stdio_client(params))
```
拉起子进程并建立到它的 stdin/stdout 通道（MCP 走 JSON-RPC over stdio）。

stdio_client(...) 返回一个 异步上下文管理器；用 exit_stack.enter_async_context(...) 注册，确保后续 __aexit__ 或 exit_stack.aclose() 能自动清理（关闭管道/结束子进程）。

await 等待子进程成功启动，拿到传输句柄。